{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from data.config import (\n",
    "    MODELS_DIR, \n",
    "    DATA_ADAPTATION_DIR, \n",
    "    TRANSFORM_MODE, \n",
    "    TRAIN_VALID_SPLIT, \n",
    "    SEED, \n",
    "    IMG_GRADIENT, \n",
    "    IMG_MODE\n",
    ")\n",
    "from dataset import CoarseMaskDataset\n",
    "from u_net import Coarse2FineTiny\n",
    "from u_net_res_attention import Coarse2FineUNetAttention\n",
    "from u_net_residual import Coarse2FineTinyRes\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51742ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir(MODELS_DIR)\n",
    "\n",
    "model_dirs = ['unetres16-32_bce-dice_18052025', 'unetres16-32_bce-dice_18052025', \n",
    "               'u_net_16_128_bce_dice', 'u_net_res_16_128_bce_dice',\n",
    "               'unet16-128_bce-dice-bound_19052025', 'unetres16-128_bce-dice-bound_19052025',\n",
    "               'unetres32-256_bce-dice-bound_21052025']\n",
    "\n",
    "model_classes = [Coarse2FineTiny, Coarse2FineTinyRes,\n",
    "                 Coarse2FineTiny, Coarse2FineTinyRes,\n",
    "                 Coarse2FineTiny, Coarse2FineTinyRes,\n",
    "                 Coarse2FineTinyRes]\n",
    "\n",
    "model_names = ['U-Net 16-128 BCE-Dice',\n",
    "               'U-Net Res 16-128 BCE-Dice',\n",
    "               'U-Net 16-128 BCE-Dice',\n",
    "               'U-Net Res 16-128 BCE-Dice',\n",
    "               'U-Net 16-128 BCE-Dice+Bound',\n",
    "               'U-Net Res 16-128 BCE-Dice+Bound',\n",
    "               'U-Net Res 32-256 BCE-Dice+Bound']\n",
    "\n",
    "losses = [[\"bce\", \"dice\"],\n",
    "         [\"bce\", \"dice\"],\n",
    "         [\"bce\", \"dice\"],\n",
    "         [\"bce\", \"dice\"],\n",
    "         [\"bce\", \"dice\", \"boundary\"],\n",
    "         [\"bce\", \"dice\", \"boundary\"],\n",
    "         [\"bce\", \"dice\", \"boundary\"]]\n",
    "\n",
    "features = [[16, 32], \n",
    "            [16, 32],\n",
    "            [16, 32, 64, 128],\n",
    "            [16, 32, 64, 128],\n",
    "            [16, 32, 64, 128],\n",
    "            [16, 32, 64, 128],\n",
    "            [32, 64, 128, 256]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(dataset, model, num_samples=5, threshold=0.5, common_title=\"Model Predictions\", column_titles=None, idx_img=None):\n",
    "    \"\"\"\n",
    "    Plots a grid of model predictions with a common title and column-specific titles.\n",
    "\n",
    "    Args:\n",
    "        dataset: PyTorch dataset returning (input, target) tuples.\n",
    "        model: Trained PyTorch model.\n",
    "        num_samples (int): Number of samples (rows) to show.\n",
    "        threshold (float): Threshold for binary mask prediction.\n",
    "        common_title (str): Title for the whole figure.\n",
    "        column_titles (list[str]): Titles for each column (4 expected).\n",
    "    \"\"\"\n",
    "    if idx_img is None:\n",
    "        idx_img = 89\n",
    "\n",
    "    n_rows = min(num_samples, len(dataset))\n",
    "    n_cols = 4  # input image, input mask, target mask, predicted mask\n",
    "\n",
    "    if column_titles is None:\n",
    "        column_titles = [\n",
    "            \"Input image\",\n",
    "            \"Input coarse mask\",\n",
    "            \"Ground truth mask\",\n",
    "            \"Predicted mask\",\n",
    "        ]\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 3))\n",
    "    fig.suptitle(common_title, fontsize=16)\n",
    "\n",
    "    device = next(model.parameters()).device  # get model's device\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        item, target = dataset[i + idx_img]  # FIXME: index offset still manual\n",
    "        item = item.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted = model(item.unsqueeze(0))\n",
    "            predicted_probs = torch.sigmoid(predicted)\n",
    "            predicted_mask = (predicted_probs > threshold).float()\n",
    "\n",
    "        images = [\n",
    "            item[0].cpu(),          # input image\n",
    "            item[1].cpu(),          # input coarse mask\n",
    "            target[0].cpu(),        # ground truth mask\n",
    "            predicted_mask[0][0].cpu(),  # predicted mask\n",
    "        ]\n",
    "\n",
    "        for j in range(n_cols):\n",
    "            ax = axes[i, j] if n_rows > 1 else axes[j]\n",
    "            ax.imshow(images[j], cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            if i == 0:\n",
    "                ax.set_title(column_titles[j], fontsize=12)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1])  # leave space for suptitle\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_checkpoint(ckpt_dir: str) -> None:\n",
    "    metrics_csv: str = os.path.join(ckpt_dir, \"metrics.csv\")\n",
    "    df: pd.DataFrame = pd.read_csv(metrics_csv)\n",
    "\n",
    "    train_df = df[df[\"train_loss\"].notnull()]\n",
    "    val_df = df[df[\"val_loss\"].notnull()]\n",
    "\n",
    "    # plot train and valid loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_df[\"step\"], train_df[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "    plt.plot(val_df[\"step\"], val_df[\"val_loss\"], label=\"Validation Loss\", marker=\"s\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.title(\"Train and Validation Loss over Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plot valid iou\n",
    "    plt.plot(val_df[\"step\"], val_df[\"val_iou\"])\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Validation Intersection over Union\")\n",
    "    plt.show()\n",
    "\n",
    "    # TODO plot other metrics if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d574658",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = CoarseMaskDataset(\n",
    "        DATA_ADAPTATION_DIR,\n",
    "        transform_type=TRANSFORM_MODE,\n",
    "        image_gradient=IMG_GRADIENT,\n",
    "        mode=IMG_MODE,\n",
    "    )\n",
    "\n",
    "total_len = len(full_dataset)\n",
    "val_len = int(total_len * TRAIN_VALID_SPLIT)\n",
    "train_len = total_len - val_len\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_len, val_len],\n",
    "    generator=torch.Generator().manual_seed(SEED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dir, model_class, model_name, loss, feat in zip(model_dirs, model_classes, model_names, losses, features):\n",
    "\n",
    "    model_path = MODELS_DIR / model_dir / \"checkpoints\" / \"best-checkpoint.ckpt\"\n",
    "\n",
    "    model = model_class.load_from_checkpoint(\n",
    "        model_path,\n",
    "        losses=loss,\n",
    "        features=feat,\n",
    "        loss_weights=[.4, .4, .2] if len(loss) == 3 else [.5, .5]\n",
    "    )\n",
    "\n",
    "    plot_result(val_dataset, model, num_samples=2, common_title=f\"{model_name} Predictions\", idx_img=8, threshold=0.4) #idx = 5 Ã¨ carino\n",
    "    #evaluate_checkpoint(os.path.join(models_dir, model_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
